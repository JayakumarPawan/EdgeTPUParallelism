{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tflite(model, input_size, n):\n",
    "    def representative_dataset():\n",
    "        for _ in range(100):\n",
    "            yield [tf.random.normal([1, *input_size])]\n",
    "\n",
    "    quantizer = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    quantizer.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    quantizer.representative_dataset = representative_dataset\n",
    "    quantizer.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "    quantizer.inference_input_type = tf.uint8  # or tf.uint8\n",
    "    quantizer.inference_output_type = tf.uint8  # or tf.uint8\n",
    "    \n",
    "    tflite_quant_model = quantizer.convert()\n",
    "\n",
    "    # Save the TFLite model to a file\n",
    "    with open(f\"models/conv2/TPU_CNN2_{n}.tflite\", \"wb\") as f:\n",
    "        f.write(tflite_quant_model)\n",
    "    print(\"saved tf lite model\")\n",
    "    return tflite_quant_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpcqs7oxhw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpcqs7oxhw/assets\n",
      "/u/pj8wfq/rl/MC/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-04-28 10:39:52.887334: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-28 10:39:52.887362: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-28 10:39:52.887570: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpcqs7oxhw\n",
      "2024-04-28 10:39:52.890111: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-28 10:39:52.890136: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpcqs7oxhw\n",
      "2024-04-28 10:39:52.895362: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-28 10:39:52.937265: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpcqs7oxhw\n",
      "2024-04-28 10:39:52.951715: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 64145 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 13, Total Ops 29, % non-converted = 44.83 %\n",
      " * 13 ARITH ops\n",
      "\n",
      "- arith.constant:   13 occurrences  (f32: 12, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 4)\n",
      "  (f32: 2)\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tf lite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpe6zudxtb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpe6zudxtb/assets\n",
      "/u/pj8wfq/rl/MC/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-04-28 10:40:15.616515: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-28 10:40:15.616543: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-28 10:40:15.616751: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpe6zudxtb\n",
      "2024-04-28 10:40:15.618580: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-28 10:40:15.618598: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpe6zudxtb\n",
      "2024-04-28 10:40:15.622891: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-28 10:40:15.655082: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpe6zudxtb\n",
      "2024-04-28 10:40:15.667374: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 50622 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 21, % non-converted = 42.86 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n",
      "\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tf lite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp5x2n2edu/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5x2n2edu/assets\n",
      "/u/pj8wfq/rl/MC/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-04-28 10:40:25.708565: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-28 10:40:25.708592: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-28 10:40:25.708797: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp5x2n2edu\n",
      "2024-04-28 10:40:25.709727: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-28 10:40:25.709738: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp5x2n2edu\n",
      "2024-04-28 10:40:25.711697: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-28 10:40:25.730670: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp5x2n2edu\n",
      "2024-04-28 10:40:25.738065: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 29269 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 5, Total Ops 12, % non-converted = 41.67 %\n",
      " * 5 ARITH ops\n",
      "\n",
      "- arith.constant:    5 occurrences  (f32: 5)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tf lite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpmkg7u59a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmkg7u59a/assets\n",
      "/u/pj8wfq/rl/MC/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-04-28 10:40:39.508694: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-28 10:40:39.508727: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-28 10:40:39.508957: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpmkg7u59a\n",
      "2024-04-28 10:40:39.509936: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-28 10:40:39.509953: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpmkg7u59a\n",
      "2024-04-28 10:40:39.512201: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-28 10:40:39.534458: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpmkg7u59a\n",
      "2024-04-28 10:40:39.543091: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 34134 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 3, Total Ops 11, % non-converted = 27.27 %\n",
      " * 3 ARITH ops\n",
      "\n",
      "- arith.constant:    3 occurrences  (f32: 3)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tf lite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpvr_abioe/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvr_abioe/assets\n",
      "/u/pj8wfq/rl/MC/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-04-28 10:40:40.850531: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-28 10:40:40.850559: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-28 10:40:40.850751: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpvr_abioe\n",
      "2024-04-28 10:40:40.852370: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-28 10:40:40.852386: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpvr_abioe\n",
      "2024-04-28 10:40:40.855804: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-28 10:40:40.887490: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpvr_abioe\n",
      "2024-04-28 10:40:40.898983: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 48231 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 10, Total Ops 21, % non-converted = 47.62 %\n",
      " * 10 ARITH ops\n",
      "\n",
      "- arith.constant:   10 occurrences  (f32: 9, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 4)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tf lite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmprbexfh_9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprbexfh_9/assets\n",
      "/u/pj8wfq/rl/MC/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-04-28 10:41:03.001394: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-28 10:41:03.001421: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-28 10:41:03.001604: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmprbexfh_9\n",
      "2024-04-28 10:41:03.002253: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-28 10:41:03.002271: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmprbexfh_9\n",
      "2024-04-28 10:41:03.004505: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-28 10:41:03.022366: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmprbexfh_9\n",
      "2024-04-28 10:41:03.030058: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 28454 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 2, Total Ops 9, % non-converted = 22.22 %\n",
      " * 2 ARITH ops\n",
      "\n",
      "- arith.constant:    2 occurrences  (f32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tf lite model\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpq7qjwi99/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpq7qjwi99/assets\n",
      "/u/pj8wfq/rl/MC/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-04-28 10:41:04.197813: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-28 10:41:04.197840: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-28 10:41:04.198025: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpq7qjwi99\n",
      "2024-04-28 10:41:04.200021: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-28 10:41:04.200044: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpq7qjwi99\n",
      "2024-04-28 10:41:04.204633: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-28 10:41:04.241017: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpq7qjwi99\n",
      "2024-04-28 10:41:04.254312: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 56287 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 11, Total Ops 24, % non-converted = 45.83 %\n",
      " * 11 ARITH ops\n",
      "\n",
      "- arith.constant:   11 occurrences  (f32: 10, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 4)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tf lite model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "src = [\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2))\n",
    "    ],  \n",
    "    [\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.GlobalAveragePooling2D()\n",
    "    ],  \n",
    "    [\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2)\n",
    "    ],\n",
    "    [\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ]\n",
    "]\n",
    "input_shapes = [(None,256,256,3), (None,125, 125, 64), (None,128, ), (None,512,)]\n",
    "for i in range(0,4):\n",
    "    a= []\n",
    "    b = []\n",
    "    for layer_group in src[i:]:\n",
    "        a.extend(layer_group)\n",
    "    if a:\n",
    "        a = tf.keras.Sequential(a)\n",
    "        a.build(input_shapes[i])\n",
    "        a.save(f\"models/conv2/GPU_CNN2_{i+4}.keras\")\n",
    "        convert_to_tflite(a, input_shapes[i][1:], i)\n",
    "    \n",
    "    for layer_group in src[:i]:\n",
    "        b.extend(layer_group)\n",
    "    if b:\n",
    "        b = tf.keras.Sequential(b)\n",
    "        b.build((None, 256, 256, 3))\n",
    "        b.save(f\"models/conv2/GPU_CNN2_{i}.keras\")\n",
    "        convert_to_tflite(b, (256,256,3), i+4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures import conv2\n",
    "model = conv2()\n",
    "model.build(tf.random.normal((256, 256, 1)))\n",
    "model.summary()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
