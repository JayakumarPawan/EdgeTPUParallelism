{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 16:54:45.909869: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-23 16:54:45.909946: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-23 16:54:46.806216: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-23 16:54:48.928837: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-23 16:55:13.128133: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 16:56:33.946699: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " depthwise_conv2d (Depthwis  (None, 220, 220, 32)      320       \n",
      " eConv2D)                                                        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 218, 218, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 109, 109, 64)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 107, 107, 64)      36928     \n",
      "                                                                 \n",
      " depthwise_conv2d_1 (Depthw  (None, 105, 105, 64)      640       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 103, 103, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 51, 51, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 49, 49, 128)       147584    \n",
      "                                                                 \n",
      " depthwise_conv2d_2 (Depthw  (None, 47, 47, 128)       1280      \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 45, 45, 256)       295168    \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 256)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 609354 (2.32 MB)\n",
      "Trainable params: 609354 (2.32 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x7fb97aa470a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def base_conv():\n",
    "    model = tf.keras.models.Sequential([\n",
    "\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "        tf.keras.layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        \n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_model():\n",
    "    # Load MNIST dataset\n",
    "\n",
    "    model = base_conv()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    # Save the trained model\n",
    "    model.save(\"models/mnist_cnn.keras\")\n",
    "    print('saved model')\n",
    "    return model\n",
    "\n",
    "create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_1a(input_size):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_size),\n",
    "        tf.keras.layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        \n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "        \n",
    "        \n",
    "    ])\n",
    "    model.build(tf.random.normal(input_size))\n",
    "    return model\n",
    "\n",
    "model = conv_1a((224, 224, 3))\n",
    "model.save(\"models/GPU_CNN_4.keras\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpke5k1ct9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpke5k1ct9/assets\n",
      "/u/pj8wfq/rl/MC/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tf lite model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 17:09:01.982503: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-23 17:09:01.982528: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-23 17:09:01.982740: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpke5k1ct9\n",
      "2024-04-23 17:09:01.983685: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-23 17:09:01.983701: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpke5k1ct9\n",
      "2024-04-23 17:09:01.985829: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-23 17:09:02.003233: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpke5k1ct9\n",
      "2024-04-23 17:09:02.010422: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 27684 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 2, Total Ops 9, % non-converted = 22.22 %\n",
      " * 2 ARITH ops\n",
      "\n",
      "- arith.constant:    2 occurrences  (f32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "def conv_1b(input_size):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        \n",
    "        tf.keras.layers.Dense(128, input_shape=input_size, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.build(tf.random.normal(input_size))\n",
    "    return model\n",
    "\n",
    "#convert one model to tflite\n",
    "def convert_to_tflite(model, input_size, n):\n",
    "    def representative_dataset():\n",
    "        for _ in range(100):\n",
    "            yield [tf.random.normal([1, *input_size])]\n",
    "\n",
    "    quantizer = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    quantizer.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    quantizer.representative_dataset = representative_dataset\n",
    "    quantizer.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "    quantizer.inference_input_type = tf.uint8  # or tf.uint8\n",
    "    quantizer.inference_output_type = tf.uint8  # or tf.uint8\n",
    "    \n",
    "    tflite_quant_model = quantizer.convert()\n",
    "\n",
    "    # Save the TFLite model to a file\n",
    "    with open(f\"models/TPU_CNN_{n}\", \"wb\") as f:\n",
    "        f.write(tflite_quant_model)\n",
    "    print(\"saved tf lite model\")\n",
    "    return tflite_quant_model\n",
    "\n",
    "input_size = (256,) \n",
    "model_tflite = conv_1b(input_size)\n",
    "model_tflite = convert_to_tflite(model_tflite, input_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "def generate_input(n):\n",
    "    return np.random.rand(n, 28, 28).astype(np.float32)\n",
    "#load model 1\n",
    "\n",
    "model_1a = tf.keras.models.load_model(\"models/mnist_dnn1a.keras\")\n",
    "start = time.perf_counter()\n",
    "outputs = model_1a.predict(generate_input(n_samples), verbose=0)\n",
    "print(outputs.shape)\n",
    "end = time.perf_counter()\n",
    "print(\"average inference time: \", (end - start)*1000/n_samples, \" ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_1b_input():\n",
    "    return np.random.rand(1,128).astype(np.float32)\n",
    "\n",
    "def tflite_inference(num_trials):\n",
    "    \n",
    "    #load model 1\n",
    "    model_1a = tf.keras.models.load_model(\"models/mnist_dnn1a.keras\")\n",
    "    \n",
    "    \n",
    "    # Load the TFLite model\n",
    "    interpreter = tf.lite.Interpreter(model_path=\"mnist_model_batched.tflite\")\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output details\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    output_scale, output_zero_point = output_details[0]['quantization']\n",
    "    input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "    \n",
    "    # Prepare input data\n",
    "    input_shape = input_details[0]['shape']\n",
    "    inference_times = []\n",
    "    inputs = [generate_1b_input() for _ in range(num_trials)]\n",
    "    for input_data in inputs:\n",
    "        start = time.perf_counter()\n",
    "        input_data = (input_data / input_scale) + input_zero_point\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.uint8))\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        output_data = output_scale * (output_data - output_zero_point)\n",
    "        end = time.perf_counter()\n",
    "        inference_times.append((end - start)*1000)\n",
    "\n",
    "    avg_inference_time = np.mean(inference_times)\n",
    "    print(\"average inference time: \", avg_inference_time, \"ms\")\n",
    "\n",
    "tflite_inference(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
