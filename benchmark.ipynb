{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_conv():\n",
    "    model = tf.keras.models.Sequential([\n",
    "\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "        tf.keras.layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        \n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_model():\n",
    "    # Load MNIST dataset\n",
    "\n",
    "    model = base_conv()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    # Save the trained model\n",
    "    model.save(\"models/mnist_cnn.keras\")\n",
    "    print('saved model')\n",
    "    return model\n",
    "\n",
    "create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_1a(input_size):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        \n",
    "        tf.keras.layers.Dense(128, activation='relu',input_shape=input_size),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "        \n",
    "        \n",
    "    ])\n",
    "    model.build(tf.random.normal(input_size))\n",
    "    return model\n",
    "\n",
    "model = conv_1a(( 256,))\n",
    "model.save(\"models/GPU_CNN_7.keras\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2twjcsvc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2twjcsvc/assets\n",
      "/u/pj8wfq/rl/MC/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-04-23 17:27:50.431773: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-23 17:27:50.431800: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-23 17:27:50.432012: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp2twjcsvc\n",
      "2024-04-23 17:27:50.434751: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-23 17:27:50.434769: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp2twjcsvc\n",
      "2024-04-23 17:27:50.440685: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-23 17:27:50.492288: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp2twjcsvc\n",
      "2024-04-23 17:27:50.511111: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 79100 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 14, Total Ops 29, % non-converted = 48.28 %\n",
      " * 14 ARITH ops\n",
      "\n",
      "- arith.constant:   14 occurrences  (f32: 13, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 6)\n",
      "  (f32: 3)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tf lite model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "def conv_1b(input_size):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_size),\n",
    "        tf.keras.layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    ])\n",
    "    model.build(tf.random.normal(input_size))\n",
    "    return model\n",
    "\n",
    "#convert one model to tflite\n",
    "def convert_to_tflite(model, input_size, n):\n",
    "    def representative_dataset():\n",
    "        for _ in range(100):\n",
    "            yield [tf.random.normal([1, *input_size])]\n",
    "\n",
    "    quantizer = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    quantizer.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    quantizer.representative_dataset = representative_dataset\n",
    "    quantizer.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "    quantizer.inference_input_type = tf.uint8  # or tf.uint8\n",
    "    quantizer.inference_output_type = tf.uint8  # or tf.uint8\n",
    "    \n",
    "    tflite_quant_model = quantizer.convert()\n",
    "\n",
    "    # Save the TFLite model to a file\n",
    "    with open(f\"models/TPU_CNN_{n}\", \"wb\") as f:\n",
    "        f.write(tflite_quant_model)\n",
    "    print(\"saved tf lite model\")\n",
    "    return tflite_quant_model\n",
    "\n",
    "input_size = (224,224,3) \n",
    "model_tflite = conv_1b(input_size)\n",
    "model_tflite = convert_to_tflite(model_tflite, input_size, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "batch_sizes = [1,4,16,64,256,1024]\n",
    "for i in range(1,5):\n",
    "    model = tf.keras.models.load_model(f\"models/GPU_CNN_{i}.keras\")\n",
    "    for batch_size in batch_sizes:\n",
    "        start = time.perf_counter()\n",
    "        outputs = model.predict(np.random.rand(n, 224, 224, 3), verbose=0)\n",
    "        end = time.perf_counter()\n",
    "        print(f\"GPU_CNN_{i} batch size {batch_size} time: {(end-start)*1000/batch_size} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_1b_input():\n",
    "    return np.random.rand(1,128).astype(np.float32)\n",
    "\n",
    "def tflite_inference(num_trials):\n",
    "    \n",
    "    #load model 1\n",
    "    model_1a = tf.keras.models.load_model(\"models/mnist_dnn1a.keras\")\n",
    "    \n",
    "    \n",
    "    # Load the TFLite model\n",
    "    interpreter = tf.lite.Interpreter(model_path=\"mnist_model_batched.tflite\")\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output details\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    output_scale, output_zero_point = output_details[0]['quantization']\n",
    "    input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "    \n",
    "    # Prepare input data\n",
    "    input_shape = input_details[0]['shape']\n",
    "    inference_times = []\n",
    "    inputs = [generate_1b_input() for _ in range(num_trials)]\n",
    "    for input_data in inputs:\n",
    "        start = time.perf_counter()\n",
    "        input_data = (input_data / input_scale) + input_zero_point\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.uint8))\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        output_data = output_scale * (output_data - output_zero_point)\n",
    "        end = time.perf_counter()\n",
    "        inference_times.append((end - start)*1000)\n",
    "\n",
    "    avg_inference_time = np.mean(inference_times)\n",
    "    print(\"average inference time: \", avg_inference_time, \"ms\")\n",
    "\n",
    "tflite_inference(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
